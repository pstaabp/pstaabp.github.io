---
title: "Chapter 13: Recursive Iteration, Rootfinding and Newton's Method"
---

[Return to all notes](index.html)

## Rootfinding and the Bisection method

Recall that we encountered the Bisection method in [Chapter 5](ch05.html).  This was another way to do rootfinding.  If we reenter the bisection procedure:
```
function result = bisect(f,a,b,options)
  arguments
    f function_handle
    a (1,1) {mustBeReal}
    b (1,1) {mustBeReal}
    options.eps (1,1) {mustBePositive} = 1e-6 
  end
   c = 0.5*(a+b); % calculate the midpoint of [a,b]
  if(b-a < options.eps)  % the interval is small enough
      result = 0.5*(a+b);
  elseif (f(c)*f(a)<0)
    result = bisect(f,a,c,'eps',options.eps);
  else
    result = bisect(f,c,b,'eps',options.eps);
  end
end
```

We can find roots, like $\sqrt{2}$ using this instead.  

```
bisect(@(x) x^2-2,0,2,1e-6)
```

### Exercise

Find the solution to $\cos x = x$ using the bisection method.  Hint: use algebra to get all terms to one side and define that 



## Recursive Iterations


Earlier, we have seen a few cases of iteration, in particular recursive iteration.  For example, the sequence:
$$a_{n} = \frac{1}{a_{n-1}+1}$$
with $a_1=1$ generates a sequence.  In [Chapter 10](ch-10.html) we found the first few terms and then found the limit of this.  Recall that if we define:
```
a=zeros(10,1,'sym');

a(1) = sym(1);
for i=2:10
    a(i) = 1/(a(i-1)+1);
end
a
```
generates the first 10 terms or
$$1,\frac{1}{2},\frac{2}{3},\frac{3}{5},\frac{5}{8},{\frac {8}{13}},{\frac {13}{21}},{\frac {21}{34}},{\frac {34}{55}},{\frac {55}{89}},{\frac {89}{144}}$$

and as we discovered above, this sequence converges to the golden mean (or golden ratio)
$$\frac{1+\sqrt{5}}{2}$$


Finding $\sqrt{a}$
------

Another useful iterative sequence is the following:
$$x_{n+1} = \frac{x_n^{2}+a}{2x_n}\qquad x_0=a$$

for a positive number $a$.  We will show that this converges to $\sqrt{a}$.  For example, if $a=2$, then

```
xval = zeros(10,1,"sym")  % make a zero 
xval(1)=1
for i=2:10
  xval(i) = (xval(i-1)^2+2)/(2*xval(i-1))
end
xval
```
The first few terms of this we get:
$$1,\frac{3}{2},\frac{17}{12},\frac{577}{408},\frac{665857}{470832},\frac{886731088897}{627013566048},\ldots$$

and then the fraction gets quite large because we declared a symbolic array, so everything is rational.  If instead, we use numeric array, like: 

```
format long
xval = zeros(6,1);  % make a zero 
xval(1)=2;
for i=2:length(xval)
  xval(i) = (xval(i-1)^2+2)/(2*xval(i-1));
end
xval
```
the result is 

$$2.0,1.500000000,1.416666666,1.414215686,1.414213562,
\ldots$$


#### Exercise.  

Use the above to find $\sqrt{5}$.  


Newton's Method
-------

(First, before trying any of these, you'll probably want to `unassign('x')` to get everything to work correctly.)


The above formula is a specific case of Newton's method for finding roots.  Here's a geometric view of Newton's method.  

We intend to find the point $x^{\star}$ such that $f(x)=0$.  We don't know how to find $x^{\star}$, but have an approximate solution, call it $x_0$.  Draw the tangent line to the curve $y=f(x)$ at $x_0$.  The following plot is an example with $f(x)=x^{2}-2$ and $x_0=0.4$:

![Newton's Method for $f(x)=x^{2}-2$](images/ch13/plot01.png)

The point on the left is $x_0=0.5$ and the green line is the tangent line there.  Instead of using the function, we use the tangent line, which is easy to solve.  That value is $x_1=2.25$.  At this point (no pun intended), we find the tangent line at $x_1$ and find where it crosses the $x$-axis.  

This process continues indefinitely and (for this example), it converges to $\sqrt{2}$.  

### Why this works

Recall that the tangent line to the curve $y=f(x)$ at $x=a$ is
$$y=f'(a)(x-a)+f(a)$$
and if we set $y=0$ in the tangent line because we are seeking the root (where the function is 0)
$$0=f'(a)(x-a)+f(a)$$
and then we solve for $x$.  (Either by hand or let Maple do it).
$$x=a+\frac{f(a)}{f'(a)}$$

Next, if we let $a=x_0$, our initial point and $x$ be $x_1$, the next point:
$$x_1=x_0+\frac{f(x_0)}{f'(x_0)}$$

or in general:
$$x_{n+1}=x_n+\frac{f(x_n)}{f'(x_n)}$$

and this last equation is called *Newton's rootfinding method* (or just *Newton's method*)


###Example

Use Newton's method to find the solution to $\cos x = x$.

If we let $f(x)=x-\cos x$ and perform Newton's method.  Since, $f'(x)=1+\sin x$, this means that
$$x_{n+1} = x_n - \frac{x_n-\cos x_n}{1+\sin x_n}$$
and let's use $x_0=0$ as an initial guess.  

If we enter:
```
xval = zeros(6,1);  % make an array of zeros
xval(1)=0;
for i=2:length(xval)
  xval(i) = xval(i-1) -(xval(i-1)-cos(xval(i-1)))/(1+sin(xval(i-1)));
end
xval
```

the results are
$$0., 1.000000000, 0.7503638679, 0.7391128909, 0.7390851334, 0.7390851332$$

As you can see from the sequence, the last two numbers are the same for the first 9 digits.  

And looking at a plot of $x$ and $\cos x$,

![Plot looking for the solution of $x=\cos x$](images/ch13/plot02.png)

The solution looks like about 0.73.  

#### Exercise

There are two $x$ values such that $1-x^{2}=\sin x$.  Find the solution that satisfies $x\lt 0$.  Plot the two function to see if your answer is reasonable.  

### Creating a Newton's Method function

The following function:
```
function result = newton(f,df,x0,options)
  arguments
    f function_handle
    df function_handle
    x0 (1,1) {mustBeReal}
    options.eps (1,1) {mustBePositive} = 1e-6 
  end

  x1=x0;
  
  dx=1; % this will be a step, just initialized to 1 to get the while loop started
  while(abs(dx)>options.eps)
    dx=f(x1)/df(x1);
    x1 = x1-dx;
  end
  result = x1;
end
```
can be used to solve Newton's method for a given function $f$, its derivative $df$ and an initial point $x0$.  

